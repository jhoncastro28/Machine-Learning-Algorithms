# â˜• AnÃ¡lisis de Machine Learning - Ingresos de CafeterÃ­as

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un anÃ¡lisis completo de Machine Learning para predecir los ingresos diarios de cafeterÃ­as utilizando mÃºltiples algoritmos. Desarrollado como parte del curso de Inteligencia Computacional de la Universidad PedagÃ³gica y TecnolÃ³gica de Colombia.

## ğŸ¯ Objetivos

- Implementar y comparar 5 algoritmos de Machine Learning diferentes
- Analizar la efectividad de cada modelo en la predicciÃ³n de ingresos
- Generar visualizaciones claras y reportes detallados
- Proporcionar una interfaz interactiva para el anÃ¡lisis
- Garantizar reproducibilidad completa de los resultados

## ğŸ¤– Algoritmos Implementados

### 1. **RegresiÃ³n Lineal**
- **Tipo**: Modelo lineal para regresiÃ³n
- **HiperparÃ¡metros**: `fit_intercept`, `normalize`
- **Ventajas**: RÃ¡pido, interpretable, sin hiperparÃ¡metros complejos

### 2. **MÃ¡quinas de Vector de Soporte (SVM)**
- **Tipo**: Algoritmo de aprendizaje supervisado
- **HiperparÃ¡metros buscados**:
  - `C`: [0.1, 1, 10, 100] - ParÃ¡metro de regularizaciÃ³n
  - `gamma`: ["scale", "auto", 0.001, 0.01, 0.1, 1] - Coeficiente del kernel
  - `kernel`: ["rbf", "linear", "poly"] - Tipo de kernel
- **Ventajas**: Efectivo en espacios de alta dimensiÃ³n

### 3. **Ãrboles de DecisiÃ³n**
- **Tipo**: Modelo de Ã¡rbol para regresiÃ³n
- **HiperparÃ¡metros buscados**:
  - `max_depth`: [3, 5, 10, 15, 20] - Profundidad mÃ¡xima
  - `min_samples_split`: [2, 5, 10, 20] - MÃ­nimo de muestras para dividir
  - `min_samples_leaf`: [1, 2, 4, 8] - MÃ­nimo de muestras por hoja
- **Ventajas**: Interpretable, maneja datos no lineales

### 4. **Random Forest**
- **Tipo**: Ensemble de Ã¡rboles de decisiÃ³n
- **HiperparÃ¡metros buscados**:
  - `n_estimators`: [50, 100, 200, 300] - NÃºmero de Ã¡rboles
  - `max_depth`: [3, 5, 10, 15] - Profundidad mÃ¡xima
  - `min_samples_split`: [2, 5, 10] - MÃ­nimo de muestras para dividir
  - `min_samples_leaf`: [1, 2, 4] - MÃ­nimo de muestras por hoja
- **Ventajas**: Robusto, reduce overfitting

### 5. **Redes Neuronales Artificiales (MLP)**
- **Tipo**: PerceptrÃ³n multicapa
- **HiperparÃ¡metros buscados**:
  - `hidden_layer_sizes`: [[50], [100], [50, 50], [100, 50]] - Arquitectura de capas
  - `activation`: ["relu", "tanh"] - FunciÃ³n de activaciÃ³n
  - `solver`: ["adam", "lbfgs"] - Algoritmo de optimizaciÃ³n
  - `alpha`: [0.0001, 0.001, 0.01] - ParÃ¡metro de regularizaciÃ³n
- **Ventajas**: Aprende patrones complejos no lineales

## ğŸ“Š Dataset

- **Fuente**: Kaggle - Coffee Shop Daily Revenue Prediction Dataset
- **Variables**: 6 caracterÃ­sticas de entrada + 1 variable objetivo
- **TamaÃ±o**: 2,000 registros
- **Objetivo**: Predecir ingresos diarios de cafeterÃ­as
- **Hash SHA-256**: `65cbae03b79e3896c6a61e4cc76b228d7468a8f2169182d34d4f6c9e93b58a2b`

### CaracterÃ­sticas del Dataset:
- `Number_of_Customers_Per_Day`: NÃºmero de clientes por dÃ­a
- `Average_Order_Value`: Valor promedio de orden
- `Operating_Hours_Per_Day`: Horas de operaciÃ³n por dÃ­a
- `Number_of_Employees`: NÃºmero de empleados
- `Marketing_Spend_Per_Day`: Gasto en marketing por dÃ­a
- `Location_Foot_Traffic`: TrÃ¡fico peatonal de la ubicaciÃ³n
- `Daily_Revenue`: Ingresos diarios (variable objetivo)

## ğŸš€ InstalaciÃ³n y Uso

### Requisitos Previos
```bash
pip install -r requirements.txt
```

### Modos de EjecuciÃ³n

#### ğŸ–¥ï¸ **Modo GUI (Interfaz GrÃ¡fica) - Recomendado**
```bash
python main.py
```
- Interfaz visual intuitiva
- Procesamiento paso a paso
- Visualizaciones integradas
- Ideal para exploraciÃ³n interactiva

#### âš¡ **Modo Batch (LÃ­nea de Comandos) - Para ProducciÃ³n**
```bash
# Ejecutar con configuraciÃ³n por defecto
python run_pipeline.py

# Ejecutar con configuraciÃ³n personalizada
python run_pipeline.py mi_config.json
```
- EjecuciÃ³n completa automatizada
- Genera todos los reportes automÃ¡ticamente
- Ideal para anÃ¡lisis repetitivos
- Genera metadatos de reproducibilidad

## ğŸ“ Estructura de Carpetas de Salida

```
reports/                          # Directorio principal de reportes
â”œâ”€â”€ run_metadata.json            # Metadatos de ejecuciÃ³n y reproducibilidad
â”œâ”€â”€ tables/                      # Tablas de resultados
â”‚   â”œâ”€â”€ comparison.csv           # ComparaciÃ³n de mÃ©tricas por modelo
â”‚   â””â”€â”€ predictions.csv          # Predicciones vs valores reales
â””â”€â”€ figures/                     # GrÃ¡ficos y visualizaciones
    â”œâ”€â”€ eda_distributions.png    # Distribuciones de variables
    â”œâ”€â”€ corr_heatmap.png         # Mapa de calor de correlaciones
    â”œâ”€â”€ scatter_pairs.png        # GrÃ¡ficos de pares de dispersiÃ³n
    â”œâ”€â”€ metrics_comparison.png   # ComparaciÃ³n de mÃ©tricas
    â””â”€â”€ predictions_vs_actual.png # Predicciones vs valores reales

models_store/                     # Modelos entrenados
â”œâ”€â”€ linear_regression.pkl        # Modelo de regresiÃ³n lineal
â”œâ”€â”€ svm.pkl                      # Modelo SVM
â”œâ”€â”€ decision_tree.pkl            # Modelo de Ã¡rbol de decisiÃ³n
â”œâ”€â”€ random_forest.pkl            # Modelo Random Forest
â”œâ”€â”€ neural_network.pkl           # Modelo de red neuronal
â””â”€â”€ scaler.pkl                   # Escalador de caracterÃ­sticas
```

## âš™ï¸ ConfiguraciÃ³n Personalizable

### Ejemplo de `config.json` Editable

```json
{
  "data": {
    "csv_path": "coffee_shop_revenue.csv",
    "target_column": "Daily_Revenue"
  },
  "preprocessing": {
    "test_size": 0.2,
    "random_state": 42,
    "scaler_type": "StandardScaler"
  },
  "models": {
    "linear_regression": {
      "enabled": true,
      "hyperparameters": {
        "fit_intercept": true,
        "normalize": false
      }
    },
    "svm": {
      "enabled": true,
      "hyperparameters": {
        "C": [0.1, 1, 10, 100],
        "gamma": ["scale", "auto", 0.001, 0.01, 0.1, 1],
        "kernel": ["rbf", "linear", "poly"]
      }
    },
    "decision_tree": {
      "enabled": true,
      "hyperparameters": {
        "max_depth": [3, 5, 10, 15, 20],
        "min_samples_split": [2, 5, 10, 20],
        "min_samples_leaf": [1, 2, 4, 8]
      }
    },
    "random_forest": {
      "enabled": true,
      "hyperparameters": {
        "n_estimators": [50, 100, 200, 300],
        "max_depth": [3, 5, 10, 15],
        "min_samples_split": [2, 5, 10],
        "min_samples_leaf": [1, 2, 4]
      }
    },
    "neural_network": {
      "enabled": true,
      "hyperparameters": {
        "hidden_layer_sizes": [[50], [100], [50, 50], [100, 50]],
        "activation": ["relu", "tanh"],
        "solver": ["adam", "lbfgs"],
        "alpha": [0.0001, 0.001, 0.01]
      }
    }
  },
  "training": {
    "cv_folds": 5,
    "n_iter": 50,
    "scoring": "neg_mean_squared_error",
    "n_jobs": -1,
    "random_state": 42
  },
  "output": {
    "reports_dir": "reports",
    "tables_dir": "reports/tables",
    "figures_dir": "reports/figures",
    "models_dir": "models_store",
    "save_models": true,
    "save_scaler": true,
    "save_predictions": true,
    "save_comparison": true
  },
  "eda": {
    "generate_plots": true,
    "save_plots": true,
    "plot_types": ["distributions", "correlations", "scatter_pairs"]
  }
}
```

### ParÃ¡metros Configurables

- **`test_size`**: ProporciÃ³n de datos para testing (0.1-0.3 recomendado)
- **`random_state`**: Semilla para reproducibilidad
- **`cv_folds`**: NÃºmero de folds para validaciÃ³n cruzada
- **`n_iter`**: Iteraciones para bÃºsqueda aleatoria de hiperparÃ¡metros
- **`n_jobs`**: NÃºmero de procesos paralelos (-1 = todos los cores)

## ğŸ“ Estructura del Proyecto

```
â”œâ”€â”€ src/                         # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ core/                   # Funcionalidades principales
â”‚   â”‚   â”œâ”€â”€ data_handler.py     # Manejo y preprocesamiento de datos
â”‚   â”‚   â””â”€â”€ model_comparator.py # ComparaciÃ³n y evaluaciÃ³n de modelos
â”‚   â”œâ”€â”€ models/                 # Algoritmos de Machine Learning
â”‚   â”‚   â”œâ”€â”€ base_model.py       # Clase base para modelos
â”‚   â”‚   â”œâ”€â”€ linear_regression.py
â”‚   â”‚   â”œâ”€â”€ svm_model.py
â”‚   â”‚   â”œâ”€â”€ decision_tree.py
â”‚   â”‚   â”œâ”€â”€ random_forest.py
â”‚   â”‚   â”œâ”€â”€ neural_network.py
â”‚   â”‚   â””â”€â”€ regression_functions.py # Funciones de entrenamiento
â”‚   â”œâ”€â”€ gui/                    # Interfaz grÃ¡fica
â”‚   â”‚   â””â”€â”€ main_window.py      # Ventana principal de la GUI
â”‚   â”œâ”€â”€ eda/                    # AnÃ¡lisis exploratorio
â”‚   â”‚   â””â”€â”€ eda_plots.py        # GeneraciÃ³n de grÃ¡ficos EDA
â”‚   â”œâ”€â”€ evaluation/             # EvaluaciÃ³n de modelos
â”‚   â”‚   â”œâ”€â”€ metrics.py          # CÃ¡lculo de mÃ©tricas
â”‚   â”‚   â””â”€â”€ plotting.py         # GrÃ¡ficos de evaluaciÃ³n
â”‚   â””â”€â”€ utils/                  # Utilidades y helpers
â”‚       â”œâ”€â”€ constants.py        # Constantes del sistema
â”‚       â”œâ”€â”€ helpers.py          # Funciones auxiliares
â”‚       â””â”€â”€ metadata.py         # GeneraciÃ³n de metadatos
â”œâ”€â”€ cli/                        # Interfaz de lÃ­nea de comandos
â”‚   â””â”€â”€ run_batch.py           # Pipeline batch reproducible
â”œâ”€â”€ main.py                     # Lanzador principal (GUI)
â”œâ”€â”€ run_pipeline.py            # Lanzador batch
â”œâ”€â”€ config.json                # ConfiguraciÃ³n del proyecto
â”œâ”€â”€ coffee_shop_revenue.csv    # Dataset de cafeterÃ­as
â”œâ”€â”€ requirements.txt           # Dependencias del proyecto
â””â”€â”€ README.md                  # DocumentaciÃ³n
```

## ğŸ® Funcionalidades

### Modo GUI
1. **Explorar y visualizar datos** - AnÃ¡lisis exploratorio completo
2. **Preparar datos** - Preprocesamiento y divisiÃ³n train/test
3. **Entrenar modelos** - Entrenamiento de los 5 algoritmos
4. **Comparar modelos** - EvaluaciÃ³n y comparaciÃ³n de rendimiento
5. **Visualizar resultados** - GrÃ¡ficos de comparaciÃ³n y anÃ¡lisis
6. **Generar reporte** - Reporte completo de resultados
7. **Guardar resultados** - Exportar resultados a CSV
8. **AnÃ¡lisis completo** - EjecuciÃ³n automÃ¡tica de todo el proceso

### Modo Batch
- **EjecuciÃ³n completa automatizada** - Todo el pipeline en una sola ejecuciÃ³n
- **GeneraciÃ³n automÃ¡tica de reportes** - Todos los archivos de salida
- **Metadatos de reproducibilidad** - InformaciÃ³n completa de la ejecuciÃ³n
- **ValidaciÃ³n de configuraciÃ³n** - VerificaciÃ³n automÃ¡tica de parÃ¡metros

## ğŸ“Š MÃ©tricas de EvaluaciÃ³n

- **MSE** (Mean Squared Error): Error cuadrÃ¡tico medio
- **RMSE** (Root Mean Squared Error): RaÃ­z del error cuadrÃ¡tico medio
- **MAE** (Mean Absolute Error): Error absoluto medio
- **RÂ²** (Coefficient of Determination): Coeficiente de determinaciÃ³n
- **MAPE** (Mean Absolute Percentage Error): Error porcentual absoluto medio

## ğŸ”’ Reproducibilidad

El proyecto garantiza **reproducibilidad completa** mediante:

- **Semillas fijas**: `random_state=42` en todos los componentes
- **Metadatos de ejecuciÃ³n**: Archivo `run_metadata.json` con:
  - Timestamp de ejecuciÃ³n
  - Versiones de todas las librerÃ­as
  - ConfiguraciÃ³n completa utilizada
  - Hash SHA-256 del dataset
  - InformaciÃ³n del sistema
- **ValidaciÃ³n automÃ¡tica**: VerificaciÃ³n de configuraciÃ³n de reproducibilidad
- **Semillas globales**: Establecimiento de semillas de numpy y Python

## ğŸ† Resultados Esperados

El anÃ¡lisis proporciona:
- Tabla comparativa de mÃ©tricas por modelo
- IdentificaciÃ³n del mejor modelo segÃºn diferentes criterios
- Visualizaciones detalladas de rendimiento
- Reporte completo con recomendaciones
- Archivos CSV con resultados exportables
- Metadatos completos para reproducibilidad

## ğŸ“ InformaciÃ³n AcadÃ©mica

**Universidad PedagÃ³gica y TecnolÃ³gica de Colombia**  
**Facultad**: IngenierÃ­a - Escuela de IngenierÃ­a de Sistemas y ComputaciÃ³n  
**Materia**: Inteligencia Computacional  

## ğŸ‘¥ Uso AcadÃ©mico

Este proyecto estÃ¡ diseÃ±ado para:
- Demostrar la implementaciÃ³n prÃ¡ctica de algoritmos ML
- Comparar diferentes enfoques de aprendizaje automÃ¡tico
- Generar reportes profesionales con visualizaciones
- Proporcionar una base para anÃ¡lisis similares
- EnseÃ±ar buenas prÃ¡cticas de reproducibilidad en ML

## ğŸ“ Notas TÃ©cnicas

- **OptimizaciÃ³n**: Se utiliza RandomizedSearchCV para optimizar hiperparÃ¡metros
- **ValidaciÃ³n**: ValidaciÃ³n cruzada de 5 folds
- **Preprocesamiento**: EstandarizaciÃ³n de caracterÃ­sticas con StandardScaler
- **Reproducibilidad**: Semillas aleatorias fijas para resultados consistentes
- **ParalelizaciÃ³n**: Uso de todos los cores disponibles (`n_jobs=-1`)
- **CachÃ©**: Sistema de cachÃ© para modelos y scalers

## ğŸ”§ PersonalizaciÃ³n

El cÃ³digo estÃ¡ diseÃ±ado para ser modular y fÃ¡cilmente extensible:

### AÃ±adir Nuevos Modelos
1. Crear clase en `src/models/`
2. Implementar funciÃ³n de entrenamiento en `regression_functions.py`
3. Agregar configuraciÃ³n en `config.json`
4. Actualizar pipeline en `run_batch.py`

### Modificar MÃ©tricas
- Editar `src/evaluation/metrics.py`
- Actualizar funciones de cÃ¡lculo en `data_handler.py`

### Personalizar Visualizaciones
- Modificar `src/eda/eda_plots.py` para grÃ¡ficos EDA
- Editar `src/evaluation/plotting.py` para grÃ¡ficos de evaluaciÃ³n

### Adaptar ConfiguraciÃ³n
- Modificar `config.json` para cambiar hiperparÃ¡metros
- Ajustar `src/utils/constants.py` para valores por defecto

## ğŸš€ Comandos RÃ¡pidos

```bash
# InstalaciÃ³n
pip install -r requirements.txt

# Modo GUI
python main.py

# Modo Batch
python run_pipeline.py

# Con configuraciÃ³n personalizada
python run_pipeline.py mi_config.json

# Verificar metadatos
cat reports/run_metadata.json
```

---

*Desarrollado con â¤ï¸ para el aprendizaje de Machine Learning*