# â˜• AnÃ¡lisis de Machine Learning - Ingresos de CafeterÃ­as

**Universidad PedagÃ³gica y TecnolÃ³gica de Colombia**  
**Facultad de IngenierÃ­a - Escuela de IngenierÃ­a de Sistemas y ComputaciÃ³n**  
**Inteligencia Computacional**

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un anÃ¡lisis completo de Machine Learning para predecir los ingresos diarios de cafeterÃ­as utilizando mÃºltiples algoritmos.

## ğŸ‘¥ Desarrolladores

Creado por estudiantes de **IngenierÃ­a de Sistemas y ComputaciÃ³n** de la **UPTC**:

- **Jhon Castro Mancipe**
- **Juan SebastiÃ¡n ZÃ¡rate**
- **Juan David Carrillo**

## ğŸ¯ Objetivos

- âœ… **Comparar 5 algoritmos de ML** diferentes en predicciÃ³n de ingresos
- âœ… **Identificar el mejor modelo** segÃºn diferentes mÃ©tricas de evaluaciÃ³n
- âœ… **Generar reportes profesionales** con visualizaciones de alta calidad
- âœ… **Proporcionar dos modos de uso**: GUI interactiva y batch automatizado
- âœ… **Garantizar reproducibilidad completa** con metadatos detallados
- âœ… **Crear un sistema modular** fÃ¡cil de extender y personalizar

## ğŸ¤– Algoritmos Implementados

### 1. **RegresiÃ³n Lineal**
- **Tipo**: Modelo lineal para regresiÃ³n
- **HiperparÃ¡metros**: `fit_intercept`, `normalize`
- **Ventajas**: RÃ¡pido, interpretable, sin hiperparÃ¡metros complejos

### 2. **MÃ¡quinas de Vector de Soporte (SVM)**
- **Tipo**: Algoritmo de aprendizaje supervisado
- **HiperparÃ¡metros buscados**:
  - `C`: [0.1, 1, 10, 100] - ParÃ¡metro de regularizaciÃ³n
  - `gamma`: ["scale", "auto", 0.001, 0.01, 0.1, 1] - Coeficiente del kernel
  - `kernel`: ["rbf", "linear", "poly"] - Tipo de kernel
- **Ventajas**: Efectivo en espacios de alta dimensiÃ³n

### 3. **Ãrboles de DecisiÃ³n**
- **Tipo**: Modelo de Ã¡rbol para regresiÃ³n
- **HiperparÃ¡metros buscados**:
  - `max_depth`: [3, 5, 10, 15, 20] - Profundidad mÃ¡xima
  - `min_samples_split`: [2, 5, 10, 20] - MÃ­nimo de muestras para dividir
  - `min_samples_leaf`: [1, 2, 4, 8] - MÃ­nimo de muestras por hoja
- **Ventajas**: Interpretable, maneja datos no lineales

### 4. **Random Forest**
- **Tipo**: Ensemble de Ã¡rboles de decisiÃ³n
- **HiperparÃ¡metros buscados**:
  - `n_estimators`: [50, 100, 200, 300] - NÃºmero de Ã¡rboles
  - `max_depth`: [3, 5, 10, 15] - Profundidad mÃ¡xima
  - `min_samples_split`: [2, 5, 10] - MÃ­nimo de muestras para dividir
  - `min_samples_leaf`: [1, 2, 4] - MÃ­nimo de muestras por hoja
- **Ventajas**: Robusto, reduce overfitting

### 5. **Redes Neuronales Artificiales (MLP)**
- **Tipo**: PerceptrÃ³n multicapa
- **HiperparÃ¡metros buscados**:
  - `hidden_layer_sizes`: [[50], [100], [50, 50], [100, 50]] - Arquitectura de capas
  - `activation`: ["relu", "tanh"] - FunciÃ³n de activaciÃ³n
  - `solver`: ["adam", "lbfgs"] - Algoritmo de optimizaciÃ³n
  - `alpha`: [0.0001, 0.001, 0.01] - ParÃ¡metro de regularizaciÃ³n
- **Ventajas**: Aprende patrones complejos no lineales

## ğŸ“Š Dataset

- **Fuente**: Kaggle - Coffee Shop Daily Revenue Prediction Dataset
- **Variables**: 6 caracterÃ­sticas de entrada + 1 variable objetivo
- **TamaÃ±o**: 2,000 registros
- **Objetivo**: Predecir ingresos diarios de cafeterÃ­as
- **Hash SHA-256**: `65cbae03b79e3896c6a61e4cc76b228d7468a8f2169182d34d4f6c9e93b58a2b`

### CaracterÃ­sticas del Dataset:
- `Number_of_Customers_Per_Day`: NÃºmero de clientes por dÃ­a
- `Average_Order_Value`: Valor promedio de orden
- `Operating_Hours_Per_Day`: Horas de operaciÃ³n por dÃ­a
- `Number_of_Employees`: NÃºmero de empleados
- `Marketing_Spend_Per_Day`: Gasto en marketing por dÃ­a
- `Location_Foot_Traffic`: TrÃ¡fico peatonal de la ubicaciÃ³n
- `Daily_Revenue`: Ingresos diarios (variable objetivo)

## ğŸš€ InstalaciÃ³n y Uso

### ğŸ“¦ **InstalaciÃ³n (Solo una vez)**
```bash
pip install -r requirements.txt
```

### ğŸ® **Modos de EjecuciÃ³n**

#### ğŸ–¥ï¸ **Modo GUI - Para ExploraciÃ³n y Aprendizaje**
```bash
python main.py
```
**Â¿QuÃ© hace?**
- Abre interfaz visual intuitiva con botones paso a paso
- Permite explorar datos, entrenar modelos y ver resultados
- Ideal para aprender y entender el proceso
- Muestra grÃ¡ficos integrados en la aplicaciÃ³n

#### âš¡ **Modo Batch - Para AnÃ¡lisis Completos y ProducciÃ³n**
```bash
# Ejecutar anÃ¡lisis completo con configuraciÃ³n por defecto
python run_pipeline.py

# Ejecutar con configuraciÃ³n personalizada
python run_pipeline.py config.json
```
**Â¿QuÃ© hace?**
- Ejecuta TODO el anÃ¡lisis automÃ¡ticamente
- Genera todos los reportes y grÃ¡ficos
- Ideal para anÃ¡lisis repetitivos o presentaciones
- Genera metadatos completos de reproducibilidad

## ğŸ“ **DÃ³nde Quedan los Resultados**

DespuÃ©s de ejecutar el anÃ¡lisis, todos los resultados se guardan en carpetas organizadas:

```
ğŸ“Š reports/                          # ğŸ¯ TODOS LOS RESULTADOS AQUÃ
â”œâ”€â”€ run_metadata.json            # ğŸ”’ Metadatos de reproducibilidad
â”œâ”€â”€ tables/                      # ğŸ“‹ Tablas de datos
â”‚   â”œâ”€â”€ comparison.csv           # ComparaciÃ³n de mÃ©tricas por modelo
â”‚   â””â”€â”€ predictions.csv          # Predicciones vs valores reales
â””â”€â”€ figures/                     # ğŸ¨ GrÃ¡ficos profesionales
    â”œâ”€â”€ eda_distributions.png    # Distribuciones de variables
    â”œâ”€â”€ corr_heatmap.png         # Mapa de calor de correlaciones
    â”œâ”€â”€ scatter_pairs.png        # GrÃ¡ficos de pares de dispersiÃ³n
    â”œâ”€â”€ metrics_comparison.png   # ComparaciÃ³n de mÃ©tricas
    â””â”€â”€ predictions_vs_actual.png # Predicciones vs valores reales

ğŸ¤– models_store/                     # Modelos entrenados listos para usar
â”œâ”€â”€ linear_regression.pkl        # Modelo de regresiÃ³n lineal
â”œâ”€â”€ svm.pkl                      # Modelo SVM
â”œâ”€â”€ decision_tree.pkl            # Modelo de Ã¡rbol de decisiÃ³n
â”œâ”€â”€ random_forest.pkl            # Modelo Random Forest
â”œâ”€â”€ neural_network.pkl           # Modelo de red neuronal
â””â”€â”€ scaler.pkl                   # Escalador de caracterÃ­sticas
```

### ğŸ“ˆ **Ejemplo de Resultados Reales**

SegÃºn el Ãºltimo anÃ¡lisis ejecutado:

| ğŸ† Modelo | MSE | RMSE | MAE | RÂ² | MAPE (%) |
|--------|-----|------|-----|----|---------| 
| **Random Forest** | 48,778 | 220.86 | 177.72 | **0.9478** | **13.63** |
| Red Neuronal | 50,382 | 224.46 | 176.54 | 0.9461 | 13.83 |
| SVM | 56,166 | 236.99 | 184.31 | 0.9399 | 14.45 |
| Ãrbol de DecisiÃ³n | 70,540 | 265.59 | 213.63 | 0.9245 | 15.86 |
| RegresiÃ³n Lineal | 97,570 | 312.36 | 244.21 | 0.8956 | 19.42 |

**ğŸ¯ Mejor modelo general: Random Forest** (mejor RÂ² y menor MAPE)

## âš™ï¸ **ConfiguraciÃ³n Personalizable**

Puedes personalizar el anÃ¡lisis editando el archivo `config.json`:

### ğŸ”§ **ParÃ¡metros Principales que Puedes Cambiar:**

- **`test_size`**: ProporciÃ³n de datos para testing (0.1-0.3 recomendado)
- **`random_state`**: Semilla para reproducibilidad (cambia para diferentes resultados)
- **`cv_folds`**: NÃºmero de folds para validaciÃ³n cruzada (3-10 recomendado)
- **`n_iter`**: Iteraciones para bÃºsqueda de hiperparÃ¡metros (mÃ¡s = mejor, pero mÃ¡s lento)
- **`n_jobs`**: NÃºmero de procesos paralelos (-1 = todos los cores)

### ğŸ“ **Ejemplo de ConfiguraciÃ³n Personalizada:**

```json
{
  "preprocessing": {
    "test_size": 0.25,        // 25% para testing
    "random_state": 123       // Semilla diferente
  },
  "training": {
    "cv_folds": 10,           // 10 folds para validaciÃ³n
    "n_iter": 100,            // 100 iteraciones de bÃºsqueda
    "n_jobs": -1              // Usar todos los cores
  },
  "models": {
    "random_forest": {
      "enabled": true,
      "hyperparameters": {
        "n_estimators": [100, 200, 500],  // MÃ¡s Ã¡rboles
        "max_depth": [10, 20, 30]         // Profundidad mayor
      }
    }
  }
}
```

### ğŸ¯ **Casos de Uso Comunes:**

- **AnÃ¡lisis rÃ¡pido**: `n_iter: 20`, `cv_folds: 3`
- **AnÃ¡lisis preciso**: `n_iter: 100`, `cv_folds: 10`
- **Solo un modelo**: Deshabilitar otros en `"enabled": false`

## ğŸ“ **Estructura del Proyecto**

```
ğŸ“‚ Machine-Learning-Algorithms/
â”œâ”€â”€ ğŸš€ main.py                     # Lanzador GUI (python main.py)
â”œâ”€â”€ âš¡ run_pipeline.py            # Lanzador batch (python run_pipeline.py)
â”œâ”€â”€ âš™ï¸ config.json                # ConfiguraciÃ³n personalizable
â”œâ”€â”€ ğŸ“Š coffee_shop_revenue.csv    # Dataset de cafeterÃ­as
â”œâ”€â”€ ğŸ“‹ requirements.txt           # Dependencias (pip install -r requirements.txt)
â”œâ”€â”€ ğŸ“– README.md                  # Esta documentaciÃ³n
â”‚
â”œâ”€â”€ ğŸ“‚ src/                       # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ ğŸ“‚ core/                  # Funcionalidades principales
â”‚   â”‚   â”œâ”€â”€ data_handler.py       # Manejo y preprocesamiento de datos
â”‚   â”‚   â””â”€â”€ model_comparator.py   # ComparaciÃ³n y evaluaciÃ³n de modelos
â”‚   â”œâ”€â”€ ğŸ“‚ models/                # Algoritmos de Machine Learning
â”‚   â”‚   â”œâ”€â”€ base_model.py         # Clase base para modelos
â”‚   â”‚   â”œâ”€â”€ linear_regression.py  # RegresiÃ³n lineal
â”‚   â”‚   â”œâ”€â”€ svm_model.py          # MÃ¡quinas de Vector de Soporte
â”‚   â”‚   â”œâ”€â”€ decision_tree.py      # Ãrboles de decisiÃ³n
â”‚   â”‚   â”œâ”€â”€ random_forest.py      # Random Forest
â”‚   â”‚   â”œâ”€â”€ neural_network.py     # Redes neuronales
â”‚   â”‚   â””â”€â”€ regression_functions.py # Funciones de entrenamiento
â”‚   â”œâ”€â”€ ğŸ“‚ gui/                   # Interfaz grÃ¡fica
â”‚   â”‚   â””â”€â”€ main_window.py        # Ventana principal de la GUI
â”‚   â”œâ”€â”€ ğŸ“‚ eda/                   # AnÃ¡lisis exploratorio
â”‚   â”‚   â””â”€â”€ eda_plots.py          # GeneraciÃ³n de grÃ¡ficos EDA
â”‚   â”œâ”€â”€ ğŸ“‚ evaluation/            # EvaluaciÃ³n de modelos
â”‚   â”‚   â”œâ”€â”€ metrics.py            # CÃ¡lculo de mÃ©tricas
â”‚   â”‚   â””â”€â”€ plotting.py           # GrÃ¡ficos de evaluaciÃ³n
â”‚   â””â”€â”€ ğŸ“‚ utils/                 # Utilidades y helpers
â”‚       â”œâ”€â”€ constants.py          # Constantes del sistema
â”‚       â”œâ”€â”€ helpers.py            # Funciones auxiliares
â”‚       â””â”€â”€ metadata.py           # GeneraciÃ³n de metadatos
â”‚
â””â”€â”€ ğŸ“‚ cli/                       # Interfaz de lÃ­nea de comandos
    â””â”€â”€ run_batch.py             # Pipeline batch reproducible
```

## ğŸ® **Funcionalidades por Modo**

### ğŸ–¥ï¸ **Modo GUI - Interactivo**
1. **ğŸ“Š Explorar y visualizar datos** - AnÃ¡lisis exploratorio completo
2. **ğŸ”§ Preparar datos** - Preprocesamiento y divisiÃ³n train/test
3. **ğŸ¤– Entrenar modelos** - Entrenamiento de los 5 algoritmos
4. **ğŸ“ˆ Comparar modelos** - EvaluaciÃ³n y comparaciÃ³n de rendimiento
5. **ğŸ¯ Visualizar resultados** - GrÃ¡ficos de comparaciÃ³n y anÃ¡lisis
6. **ğŸ“‹ Generar reporte** - Reporte completo de resultados
7. **ğŸ’¾ Guardar resultados** - Exportar resultados a CSV
8. **ğŸš€ AnÃ¡lisis completo** - EjecuciÃ³n automÃ¡tica de todo el proceso

### âš¡ **Modo Batch - Automatizado**
- **ğŸ”„ EjecuciÃ³n completa automatizada** - Todo el pipeline en una sola ejecuciÃ³n
- **ğŸ“Š GeneraciÃ³n automÃ¡tica de reportes** - Todos los archivos de salida
- **ğŸ”’ Metadatos de reproducibilidad** - InformaciÃ³n completa de la ejecuciÃ³n
- **âœ… ValidaciÃ³n de configuraciÃ³n** - VerificaciÃ³n automÃ¡tica de parÃ¡metros
- **âš¡ Procesamiento paralelo** - Usa todos los cores disponibles

## ğŸ“Š **MÃ©tricas de EvaluaciÃ³n**

El sistema evalÃºa cada modelo con 5 mÃ©tricas estÃ¡ndar:

- **ğŸ“‰ MSE** (Mean Squared Error): Error cuadrÃ¡tico medio - Penaliza errores grandes
- **ğŸ“ RMSE** (Root Mean Squared Error): RaÃ­z del error cuadrÃ¡tico medio - En las mismas unidades que el target
- **ğŸ“ MAE** (Mean Absolute Error): Error absoluto medio - Promedio de errores absolutos
- **ğŸ“ˆ RÂ²** (Coefficient of Determination): Coeficiente de determinaciÃ³n - ProporciÃ³n de varianza explicada (0-1)
- **ğŸ“Š MAPE** (Mean Absolute Percentage Error): Error porcentual absoluto medio - Error relativo en porcentaje

### ğŸ¯ **InterpretaciÃ³n de MÃ©tricas:**
- **MSE, RMSE, MAE, MAPE**: **Menor es mejor** (0 = perfecto)
- **RÂ²**: **Mayor es mejor** (1 = perfecto, 0 = no mejor que el promedio)

## ğŸ”’ **Reproducibilidad Garantizada**

El proyecto garantiza **reproducibilidad completa** mediante:

- **ğŸ² Semillas fijas**: `random_state=42` en todos los componentes
- **ğŸ“‹ Metadatos de ejecuciÃ³n**: Archivo `run_metadata.json` con:
  - Timestamp de ejecuciÃ³n
  - Versiones de todas las librerÃ­as
  - ConfiguraciÃ³n completa utilizada
  - Hash SHA-256 del dataset
  - InformaciÃ³n del sistema
- **âœ… ValidaciÃ³n automÃ¡tica**: VerificaciÃ³n de configuraciÃ³n de reproducibilidad
- **ğŸŒ± Semillas globales**: Establecimiento de semillas de numpy y Python

## ğŸ† **Resultados que Obtienes**

DespuÃ©s de ejecutar el anÃ¡lisis, obtienes:

- **ğŸ“Š Tabla comparativa** de mÃ©tricas por modelo
- **ğŸ† IdentificaciÃ³n del mejor modelo** segÃºn diferentes criterios
- **ğŸ¨ Visualizaciones profesionales** listas para presentar
- **ğŸ“‹ Reporte completo** con recomendaciones
- **ğŸ’¾ Archivos CSV** con resultados exportables
- **ğŸ”’ Metadatos completos** para reproducibilidad
- **ğŸ¤– Modelos entrenados** listos para usar en producciÃ³n

## ğŸ“ **InformaciÃ³n AcadÃ©mica**

**Universidad PedagÃ³gica y TecnolÃ³gica de Colombia**  
**Facultad**: IngenierÃ­a - Escuela de IngenierÃ­a de Sistemas y ComputaciÃ³n  
**Materia**: Inteligencia Computacional  

## ğŸ‘¥ **Uso AcadÃ©mico**

Este proyecto estÃ¡ diseÃ±ado para:
- âœ… **Demostrar la implementaciÃ³n prÃ¡ctica** de algoritmos ML
- âœ… **Comparar diferentes enfoques** de aprendizaje automÃ¡tico
- âœ… **Generar reportes profesionales** con visualizaciones
- âœ… **Proporcionar una base** para anÃ¡lisis similares
- âœ… **EnseÃ±ar buenas prÃ¡cticas** de reproducibilidad en ML
- âœ… **Mostrar el flujo completo** de un proyecto de ML profesional

## ğŸ“ **Notas TÃ©cnicas**

- **ğŸ” OptimizaciÃ³n**: RandomizedSearchCV para bÃºsqueda eficiente de hiperparÃ¡metros
- **âœ… ValidaciÃ³n**: ValidaciÃ³n cruzada de 5 folds por defecto
- **ğŸ”§ Preprocesamiento**: EstandarizaciÃ³n con StandardScaler
- **ğŸ² Reproducibilidad**: Semillas aleatorias fijas para resultados consistentes
- **âš¡ ParalelizaciÃ³n**: Uso de todos los cores disponibles (`n_jobs=-1`)
- **ğŸ’¾ CachÃ©**: Sistema de cachÃ© para modelos y scalers

## ğŸš€ **Comandos RÃ¡pidos**

```bash
# ğŸ“¦ InstalaciÃ³n
pip install -r requirements.txt

# ğŸ–¥ï¸ Modo GUI
python main.py

# âš¡ Modo Batch
python run_pipeline.py

# âš™ï¸ Con configuraciÃ³n personalizada
python run_pipeline.py config.json

# ğŸ“‹ Verificar metadatos
cat reports/run_metadata.json
```

---

*Desarrollado con â¤ï¸ para el aprendizaje de Machine Learning*